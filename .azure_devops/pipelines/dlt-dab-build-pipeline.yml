variables:
  # Set environment specific variables based on the name of the source branch
  - ${{ if eq(replace(variables['Build.SourceBranch'], 'refs/heads/', ''), 'main') }}:
      - group: DLT_DAB_ENV_PROD
      - name: TARGET
        value: "prod"
  - ${{ elseif eq(replace(variables['Build.SourceBranch'], 'refs/heads/', ''), 'staging') }}:
      - group: DLT_DAB_ENV_STG
      - name: TARGET
        value: "staging"
  - ${{ elseif eq(replace(variables['Build.SourceBranch'], 'refs/heads/', ''), 'development') }}:
      - group: DLT_DAB_ENV_DEV
      - name: TARGET
        value: "dev"

  # Set test environment variables
  - group: DLT_DAB_ENV_DEV_TEST

  # Others
  - name: GIT_BRANCH
    value: $[replace(variables['Build.SourceBranch'], 'refs/heads/', '')]

# trigger:
#   batch: true
#   branches:
#     include:
#       - "development"
#       - "staging"
#       - "main"
#   paths:
#     exclude: # Exclude files from triggering the pipeline
#       # - ".azure_devops/*"
#       - ".github/*"
#       - "README.md"

pr:
  branches:
    include:
      - "development"
      - "staging"
      - "main"
  paths:
    exclude: # Exclude files from triggering the pipeline
      - ".github/*"
      - "README.md"

stages:
  - stage: onPush
    jobs:
      - job: onPushJob
        pool:
          vmImage: "ubuntu-20.04"

        steps:
          #########################################################
          # Init actions
          #########################################################

          - script: env | sort
            workingDirectory: "$(System.DefaultWorkingDirectory)"
            displayName: "List environment / context"

          - task: UsePythonVersion@0
            displayName: "Use Python 3.10"
            inputs:
              versionSpec: 3.10

          - checkout: self
            persistCredentials: true
            clean: true
            fetchDepth: 0
            displayName: "Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)"

          - script: |
              curl -sSL https://install.python-poetry.org | python -
              export PATH=$PATH:$HOME/.poetry/bin
              poetry install --no-root
            displayName: "Install dependencies"

          - script: echo "##vso[task.prependpath]$HOME/.poetry/bin"
            displayName: Add poetry to PATH

          - script: |
              curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
            workingDirectory: "$(System.DefaultWorkingDirectory)"
            displayName: "Install Databricks CLI"

          #########################################################
          # Execute unit and integration tests in TEST environment
          #########################################################

          - script: |
              databricks bundle deploy --target dev_test
            env:
              DATABRICKS_HOST: $(DATABRICKS_TEST_HOST)
              DATABRICKS_CLIENT_ID: $(DATABRICKS_TEST_CLIENT_ID)
              DATABRICKS_CLIENT_SECRET: $(DATABRICKS_TEST_CLIENT_SECRET)
            workingDirectory: "$(System.DefaultWorkingDirectory)"
            displayName: "Deploy bundle to dev test"

          # - script: |
          #     nutter run $(ROOT_PATH)/files/tests/notebook_unit/ $(CLUSTER_ID) --recursive --junit_report --timeout 600
          #   env:
          #     DATABRICKS_HOST: $(DATABRICKS_HOST)
          #     DATABRICKS_CLIENT_ID: $(DATABRICKS_CLIENT_ID)
          #     DATABRICKS_CLIENT_SECRET: $(DATABRICKS_CLIENT_SECRET)
          #   workingDirectory: "$(System.DefaultWorkingDirectory)"
          #   displayName: "Execute Nutter based unit tests"

          - script: |
              poetry run pytest tests/unit-local --junit-xml=test-local.xml --cov-report=xml:./coverage-reports/coverage-pytest.xml --cov
            env:
              DATABRICKS_HOST: $(DATABRICKS_TEST_HOST)
              DATABRICKS_CLIENT_ID: $(DATABRICKS_TEST_CLIENT_ID)
              DATABRICKS_CLIENT_SECRET: $(DATABRICKS_TEST_CLIENT_SECRET)
              DATABRICKS_CLUSTER_ID: $(TEST_CLUSTER_ID)
            displayName: "Execute Pytest unit tests"

          #########################################################
          # Build and execute integration tests
          #########################################################

          - script: |
              set -e
              set -x
              DLT_START=$SECONDS
              DLT_START_ISO=$(date --iso-8601=seconds)
              databricks bundle run integration_test --target dev_test 2> >(tee -a test_stderr.log)
              DLT_ERRORS = $?
              DLT_FINISH=$SECONDS
              echo "Writing JUnit report for DLT test"
              echo "<?xml version=\"1.0\" encoding=\"UTF-8\"?><testsuites><testsuite name=\"DLT Integration test\" tests=\"1\" skipped=\"0\" errors=\"$DLT_ERRORS\" failures=\"$DLT_ERRORS\" time=\"$((DLT_FINISH-DLT_START))\" timestamp=\"${DLT_START_ISO}\">" > test-dlt.xml
              echo "<testcase classname=\"DLTIntegration\" name=\"Integration test\" time=\"$((DLT_FINISH-DLT_START))\">" >> test-dlt.xml
              if [ "$DLT_ERRORS" = "1" ]; then
                echo "<failure message=\"DLT test failure\">" >> test-dlt.xml
                cat test_stderr.log >> test-dlt.xml
                echo "</failure>" >> test-dlt.xml
              echo '</testcase></testsuite></testsuites>' >> test-dlt.xml
            env:
              DATABRICKS_HOST: $(DATABRICKS_TEST_HOST)
              DATABRICKS_CLIENT_ID: $(DATABRICKS_TEST_CLIENT_ID)
              DATABRICKS_CLIENT_SECRET: $(DATABRICKS_TEST_CLIENT_SECRET)
            displayName: "Execute DLT Integration Test pipeline"

          - script: |
              databricks bundle run --target dev_test --validate-only my_project_pipeline
            env:
              DATABRICKS_HOST: $(DATABRICKS_TEST_HOST)
              DATABRICKS_CLIENT_ID: $(DATABRICKS_TEST_CLIENT_ID)
              DATABRICKS_CLIENT_SECRET: $(DATABRICKS_TEST_CLIENT_SECRET)
            workingDirectory: "$(System.DefaultWorkingDirectory)"
            displayName: "Validate DLT pipeline"

          #########################################################
          # Validate bundle against target environment
          #########################################################

          - script: |
              echo $(TARGET)
              databricks bundle validate --target $(TARGET)
            env:
              DATABRICKS_HOST: $(DATABRICKS_HOST)
              DATABRICKS_CLIENT_ID: $(DATABRICKS_CLIENT_ID)
              DATABRICKS_CLIENT_SECRET: $(DATABRICKS_CLIENT_SECRET)
              DATABRICKS_BUNDLE_TARGET: $(TARGET)
            workingDirectory: "$(System.DefaultWorkingDirectory)"
            displayName: "Validate bundle"
            condition: and(succeeded(), in(variables['TARGET'], 'dev', 'staging', 'prod'))

          #########################################################
          # Publish artifacts
          #########################################################

          - task: ArchiveFiles@2
            condition: in(variables['GIT_BRANCH'], 'development', 'staging', 'main')
            inputs:
              rootFolderOrFile: "$(System.DefaultWorkingDirectory)"
              includeRootFolder: false
              archiveType: zip
              archiveFile: $(Build.ArtifactStagingDirectory)/$(Build.BuildId).zip
              replaceExistingArchive: true
            displayName: "Archive files"

          # Publish code coverage results v2
          # Publish any of the code coverage results from a build.
          - task: PublishCodeCoverageResults@2
            inputs:
              codeCoverageTool: "Cobertura" # pytest-cov generates a Cobertura-style XML report
              summaryFileLocation: "$(System.DefaultWorkingDirectory)/coverage-reports/coverage-pytest.xml"
              #pathToSources: # string. Path to Source files.

          - task: PublishBuildArtifacts@1
            condition: in(variables['GIT_BRANCH'], 'development', 'staging', 'main')
            inputs:
              PathtoPublish: "$(Build.ArtifactStagingDirectory)/$(Build.BuildId).zip"
              artifactName: "drop"
            displayName: "Upload build_$(Build.BuildId).zip to artifacts"

          #########################################################
          # Process test results
          #########################################################

          - task: PublishTestResults@2
            condition: succeededOrFailed()
            inputs:
              testResultsFormat: "JUnit"
              testResultsFiles: "**/test-*.xml"
              failTaskOnFailedTests: true
            displayName: "Publish test results"